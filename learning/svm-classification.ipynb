{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform document classification analysis on the ScikitLearn newsgoup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (15, 6)\n",
    "\n",
    "# Do not use normal form (scietific notation) when printing numbers, exponents can make it harder to compare values\n",
    "pd.set_option('float_format', '{:f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'numpy: 1.14.3, pandas: 0.23.0, sklearn: 0.19.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'numpy: {}, pandas: {}, sklearn: {}'.format(np.__version__, pd.__version__, sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR', 'description'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 20 newsgroups by date dataset\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View sample document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View newsgroup names, these are the text representations of the target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View newsgroup target values in numeric form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4, 4, ..., 3, 1, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "\n",
    "# Requires a bag of wors as it's input\n",
    "# Get a score for every (doc_id, word_id)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "# The CountVectorizer plus the TfidfTransformer is equal to the TfidfVectoriser\n",
    "\n",
    "\n",
    "# the tfidf vectoriser works directly on documents and produces a bag of words wth corresponding tfidf scores\n",
    "\n",
    "\n",
    "# Use the HashVectoriser instead of CountVectorizer when there is a very large vocabulary of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use an SVM estimator to predict the target newsgroup. When the loss goes below the `tol` training stops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf_svc = LinearSVC(penalty=\"l2\", dual=False, tol=1e-3)\n",
    "clf_svc.fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain the transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf_svc_pipeline = Pipeline([\n",
    "    (\"vect\", CountVectorizer()),\n",
    "    (\"tfidf\", TfidfTransformer()),\n",
    "    (\"clf\", LinearSVC(penalty=\"l2\", dual=False, tol=0.001))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svc_pipeline.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_test = fetch_20newsgroups(subset=\"test\", shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the test data through the transformation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf_svc_pipeline.predict(twenty_test.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11314, 130107), (11314, 130107))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape, X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the Tfidf scores for one document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 56979)\t0.0574701540748513\n",
      "  (0, 75358)\t0.3538350134970617\n",
      "  (0, 123162)\t0.25970902457356887\n",
      "  (0, 118280)\t0.21186807208281694\n",
      "  (0, 50527)\t0.05461428658858725\n",
      "  (0, 124031)\t0.10798795154169123\n",
      "  (0, 85354)\t0.03696978508816317\n",
      "  (0, 114688)\t0.06214070986309587\n",
      "  (0, 111322)\t0.019156718024950434\n",
      "  (0, 123984)\t0.036854292634593756\n",
      "  (0, 37780)\t0.3813389125949312\n",
      "  (0, 68532)\t0.07325812342131598\n",
      "  (0, 114731)\t0.1444727551278406\n",
      "  (0, 87620)\t0.0356718631408158\n",
      "  (0, 95162)\t0.03447138409326312\n",
      "  (0, 64095)\t0.035420924271313554\n",
      "  (0, 98949)\t0.16068606055394935\n",
      "  (0, 90379)\t0.01992885995664587\n",
      "  (0, 118983)\t0.03708597805061915\n",
      "  (0, 89362)\t0.06521174306303765\n",
      "  (0, 79666)\t0.10936401252414275\n",
      "  (0, 40998)\t0.07801368196918111\n",
      "  (0, 92081)\t0.09913274493911224\n",
      "  (0, 76032)\t0.01921946305222309\n",
      "  (0, 4605)\t0.06332603952480324\n",
      "  :\t:\n",
      "  (0, 37565)\t0.03431760442478462\n",
      "  (0, 113986)\t0.17691750674853085\n",
      "  (0, 83256)\t0.08844382496462175\n",
      "  (0, 86001)\t0.07000411445838192\n",
      "  (0, 51730)\t0.09714744057976724\n",
      "  (0, 109271)\t0.10844724822064675\n",
      "  (0, 128026)\t0.06062209588975889\n",
      "  (0, 96144)\t0.10826904490745742\n",
      "  (0, 78784)\t0.0633940918806495\n",
      "  (0, 63363)\t0.08342748387969037\n",
      "  (0, 90252)\t0.03188936879541757\n",
      "  (0, 123989)\t0.08207027465330355\n",
      "  (0, 67156)\t0.0731344392274018\n",
      "  (0, 128402)\t0.059222940832778424\n",
      "  (0, 62221)\t0.029215279924278678\n",
      "  (0, 57308)\t0.15587170091577043\n",
      "  (0, 76722)\t0.06908779999621749\n",
      "  (0, 94362)\t0.05545703139014723\n",
      "  (0, 78955)\t0.059898568880615996\n",
      "  (0, 114428)\t0.05511105154696677\n",
      "  (0, 66098)\t0.09785515708314482\n",
      "  (0, 35187)\t0.09353930598317126\n",
      "  (0, 35983)\t0.037704485636198756\n",
      "  (0, 128420)\t0.042784990792830935\n",
      "  (0, 86580)\t0.1315711871424099\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every word is identified by (document_id, word_id) : frequency. Get the word frequencies for the first document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 86580)\t1\n",
      "  (0, 128420)\t1\n",
      "  (0, 35983)\t1\n",
      "  (0, 35187)\t1\n",
      "  (0, 66098)\t1\n",
      "  (0, 114428)\t1\n",
      "  (0, 78955)\t1\n",
      "  (0, 94362)\t1\n",
      "  (0, 76722)\t1\n",
      "  (0, 57308)\t1\n",
      "  (0, 62221)\t1\n",
      "  (0, 128402)\t2\n",
      "  (0, 67156)\t1\n",
      "  (0, 123989)\t1\n",
      "  (0, 90252)\t1\n",
      "  (0, 63363)\t1\n",
      "  (0, 78784)\t1\n",
      "  (0, 96144)\t1\n",
      "  (0, 128026)\t1\n",
      "  (0, 109271)\t1\n",
      "  (0, 51730)\t1\n",
      "  (0, 86001)\t1\n",
      "  (0, 83256)\t1\n",
      "  (0, 113986)\t1\n",
      "  (0, 37565)\t1\n",
      "  :\t:\n",
      "  (0, 4605)\t1\n",
      "  (0, 76032)\t1\n",
      "  (0, 92081)\t1\n",
      "  (0, 40998)\t1\n",
      "  (0, 79666)\t1\n",
      "  (0, 89362)\t3\n",
      "  (0, 118983)\t1\n",
      "  (0, 90379)\t1\n",
      "  (0, 98949)\t1\n",
      "  (0, 64095)\t1\n",
      "  (0, 95162)\t1\n",
      "  (0, 87620)\t1\n",
      "  (0, 114731)\t5\n",
      "  (0, 68532)\t3\n",
      "  (0, 37780)\t5\n",
      "  (0, 123984)\t1\n",
      "  (0, 111322)\t1\n",
      "  (0, 114688)\t1\n",
      "  (0, 85354)\t1\n",
      "  (0, 124031)\t2\n",
      "  (0, 50527)\t2\n",
      "  (0, 118280)\t2\n",
      "  (0, 123162)\t2\n",
      "  (0, 75358)\t2\n",
      "  (0, 56979)\t3\n"
     ]
    }
   ],
   "source": [
    "print(X_train_counts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the prediction accurancy, how many predicted are equal to the actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8534253850238981"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_svm = accuracy_score(twenty_test.target, predicted)\n",
    "acc_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
